{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Goal: Apply sentiment analysis on dataset from RateMyProfessors. The project will take in student comments and make predictions on the students star and difficulty rating for the professor."
      ],
      "metadata": {
        "id": "cV-6ZvUpfILN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: Will be using the term star instead of quality, since Dr. Hibo Je's dataset uses the term star. Hence, student star rating will mean the student quality rating."
      ],
      "metadata": {
        "id": "DFZYBoc7lZRi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import necessary libraries"
      ],
      "metadata": {
        "id": "5A62v2g_0zaX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m6gzB0X3KArL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a18a1a45-74f8-4241-b6d9-bd86d8a91cea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nlpaug in /usr/local/lib/python3.10/dist-packages (1.1.11)\n",
            "Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (1.5.3)\n",
            "Requirement already satisfied: gdown>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (4.6.6)\n",
            "Requirement already satisfied: numpy>=1.16.2 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (1.22.4)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (2.27.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (4.11.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (4.65.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (3.12.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->nlpaug) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->nlpaug) (2.8.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (2022.12.7)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug) (2.4.1)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (1.7.1)\n",
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ]
        }
      ],
      "source": [
        "!pip install nlpaug\n",
        "%load_ext tensorboard\n",
        "from google.colab import drive\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "import datetime\n",
        "import string\n",
        "import matplotlib.pyplot as plt\n",
        "import nlpaug.augmenter.word as naw\n",
        "import nltk\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Enable GPU\n",
        "# Confirm connection to GPU with TensorFlow\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSzHCIlAGYRm",
        "outputId": "b2ca663a-e92c-44ae-d4a5-0e31255a8849"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load and view data\n",
        "\n",
        "Data from https://data.mendeley.com/datasets/fvtfjyvw7d/2"
      ],
      "metadata": {
        "id": "aBi83Z2F0_Tw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "drive.mount('/content/drive')\n",
        "df = pd.read_csv(\"./drive/MyDrive/Datasets/RateMyProfessor_Sample_data.csv\")\n",
        "print(df.head(3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ri2On41XK82i",
        "outputId": "b73fe82f-860b-41f5-ac08-34156dca13fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "   professor_name                                 school_name  \\\n",
            "0  Leslie  Looney  University Of Illinois at Urbana-Champaign   \n",
            "1  Leslie  Looney  University Of Illinois at Urbana-Champaign   \n",
            "2  Leslie  Looney  University Of Illinois at Urbana-Champaign   \n",
            "\n",
            "        department_name                    local_name state_name  \\\n",
            "0  Astronomy department   Champaign\\xe2\\x80\\x93Urbana         IL   \n",
            "1  Astronomy department   Champaign\\xe2\\x80\\x93Urbana         IL   \n",
            "2  Astronomy department   Champaign\\xe2\\x80\\x93Urbana         IL   \n",
            "\n",
            "   year_since_first_review  star_rating take_again  diff_index  \\\n",
            "0                     11.0          4.7        NaN         2.0   \n",
            "1                     11.0          4.7        NaN         2.0   \n",
            "2                     11.0          4.7        NaN         2.0   \n",
            "\n",
            "                                       tag_professor  ...  lots_of_homework  \\\n",
            "0  Hilarious (2)  GROUP PROJECTS (2)  Gives good ...  ...                 0   \n",
            "1  Hilarious (2)  GROUP PROJECTS (2)  Gives good ...  ...                 0   \n",
            "2  Hilarious (2)  GROUP PROJECTS (2)  Gives good ...  ...                 0   \n",
            "\n",
            "  accessible_outside_class lecture_heavy extra_credit  graded_by_few_things  \\\n",
            "0                        0             0            0                     0   \n",
            "1                        0             0            0                     0   \n",
            "2                        0             0            0                     0   \n",
            "\n",
            "   group_projects test_heavy so_many_papers beware_of_pop_quizzes  \\\n",
            "0               1          0              0                     0   \n",
            "1               1          0              0                     0   \n",
            "2               1          0              0                     0   \n",
            "\n",
            "  IsCourseOnline  \n",
            "0              0  \n",
            "1              0  \n",
            "2              0  \n",
            "\n",
            "[3 rows x 51 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "qadTiIOONGMX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cab0a19-193b-43e6-c6e2-ac859214a20c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 20000 entries, 0 to 19999\n",
            "Data columns (total 51 columns):\n",
            " #   Column                    Non-Null Count  Dtype  \n",
            "---  ------                    --------------  -----  \n",
            " 0   professor_name            20000 non-null  object \n",
            " 1   school_name               20000 non-null  object \n",
            " 2   department_name           20000 non-null  object \n",
            " 3   local_name                20000 non-null  object \n",
            " 4   state_name                20000 non-null  object \n",
            " 5   year_since_first_review   20000 non-null  float64\n",
            " 6   star_rating               20000 non-null  float64\n",
            " 7   take_again                2998 non-null   object \n",
            " 8   diff_index                20000 non-null  float64\n",
            " 9   tag_professor             11093 non-null  object \n",
            " 10  num_student               20000 non-null  float64\n",
            " 11  post_date                 19995 non-null  object \n",
            " 12  name_onlines              20000 non-null  object \n",
            " 13  name_not_onlines          19995 non-null  object \n",
            " 14  student_star              19995 non-null  float64\n",
            " 15  student_difficult         19995 non-null  float64\n",
            " 16  attence                   4009 non-null   object \n",
            " 17  for_credits               4053 non-null   object \n",
            " 18  would_take_agains         2582 non-null   object \n",
            " 19  grades                    3292 non-null   object \n",
            " 20  help_useful               20000 non-null  float64\n",
            " 21  help_not_useful           20000 non-null  float64\n",
            " 22  comments                  19993 non-null  object \n",
            " 23  word_comment              19993 non-null  float64\n",
            " 24  gender                    20000 non-null  object \n",
            " 25  race                      20000 non-null  object \n",
            " 26  asian                     20000 non-null  float64\n",
            " 27  hispanic                  20000 non-null  float64\n",
            " 28  nh_black                  20000 non-null  float64\n",
            " 29  nh_white                  20000 non-null  float64\n",
            " 30  gives_good_feedback       20000 non-null  int64  \n",
            " 31  caring                    20000 non-null  int64  \n",
            " 32  respected                 20000 non-null  int64  \n",
            " 33  participation_matters     20000 non-null  int64  \n",
            " 34  clear_grading_criteria    20000 non-null  int64  \n",
            " 35  skip_class                20000 non-null  int64  \n",
            " 36  amazing_lectures          20000 non-null  int64  \n",
            " 37  inspirational             20000 non-null  int64  \n",
            " 38  tough_grader              20000 non-null  int64  \n",
            " 39  hilarious                 20000 non-null  int64  \n",
            " 40  get_ready_to_read         20000 non-null  int64  \n",
            " 41  lots_of_homework          20000 non-null  int64  \n",
            " 42  accessible_outside_class  20000 non-null  int64  \n",
            " 43  lecture_heavy             20000 non-null  int64  \n",
            " 44  extra_credit              20000 non-null  int64  \n",
            " 45  graded_by_few_things      20000 non-null  int64  \n",
            " 46  group_projects            20000 non-null  int64  \n",
            " 47  test_heavy                20000 non-null  int64  \n",
            " 48  so_many_papers            20000 non-null  int64  \n",
            " 49  beware_of_pop_quizzes     20000 non-null  int64  \n",
            " 50  IsCourseOnline            20000 non-null  int64  \n",
            "dtypes: float64(13), int64(21), object(17)\n",
            "memory usage: 7.8+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check types of the features\n",
        "df.dtypes"
      ],
      "metadata": {
        "id": "ueeNjTyq3HpC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cc38d6a-7b88-4f61-b66c-746e593b0caf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "professor_name               object\n",
              "school_name                  object\n",
              "department_name              object\n",
              "local_name                   object\n",
              "state_name                   object\n",
              "year_since_first_review     float64\n",
              "star_rating                 float64\n",
              "take_again                   object\n",
              "diff_index                  float64\n",
              "tag_professor                object\n",
              "num_student                 float64\n",
              "post_date                    object\n",
              "name_onlines                 object\n",
              "name_not_onlines             object\n",
              "student_star                float64\n",
              "student_difficult           float64\n",
              "attence                      object\n",
              "for_credits                  object\n",
              "would_take_agains            object\n",
              "grades                       object\n",
              "help_useful                 float64\n",
              "help_not_useful             float64\n",
              "comments                     object\n",
              "word_comment                float64\n",
              "gender                       object\n",
              "race                         object\n",
              "asian                       float64\n",
              "hispanic                    float64\n",
              "nh_black                    float64\n",
              "nh_white                    float64\n",
              "gives_good_feedback           int64\n",
              "caring                        int64\n",
              "respected                     int64\n",
              "participation_matters         int64\n",
              "clear_grading_criteria        int64\n",
              "skip_class                    int64\n",
              "amazing_lectures              int64\n",
              "inspirational                 int64\n",
              "tough_grader                  int64\n",
              "hilarious                     int64\n",
              "get_ready_to_read             int64\n",
              "lots_of_homework              int64\n",
              "accessible_outside_class      int64\n",
              "lecture_heavy                 int64\n",
              "extra_credit                  int64\n",
              "graded_by_few_things          int64\n",
              "group_projects                int64\n",
              "test_heavy                    int64\n",
              "so_many_papers                int64\n",
              "beware_of_pop_quizzes         int64\n",
              "IsCourseOnline                int64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract data and pre-process"
      ],
      "metadata": {
        "id": "7Syn6eCrOyd1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract comments and the 2 labels\n",
        "df = df.iloc[:, [22, 14, 15]]\n",
        "df.head(3)"
      ],
      "metadata": {
        "id": "dWKJU7g_6chg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "a7d368a5-440f-45c5-86a3-605f0bc24cdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            comments  student_star  \\\n",
              "0  This class is hard, but its a two-in-one gen-e...           5.0   \n",
              "1  Definitely going to choose Prof. Looney\\'s cla...           5.0   \n",
              "2  I overall enjoyed this class because the assig...           4.0   \n",
              "\n",
              "   student_difficult  \n",
              "0                3.0  \n",
              "1                2.0  \n",
              "2                3.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-60ffc52e-8d54-4ba2-82a0-4662313d8096\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comments</th>\n",
              "      <th>student_star</th>\n",
              "      <th>student_difficult</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>This class is hard, but its a two-in-one gen-e...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Definitely going to choose Prof. Looney\\'s cla...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I overall enjoyed this class because the assig...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-60ffc52e-8d54-4ba2-82a0-4662313d8096')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-60ffc52e-8d54-4ba2-82a0-4662313d8096 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-60ffc52e-8d54-4ba2-82a0-4662313d8096');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find any NaN in the two labels\n",
        "print(np.where(np.isnan(df['student_star'])))\n",
        "print(np.where(np.isnan(df['student_difficult'])))\n",
        "\n",
        "# Drop the observations that contain a NaN(s) as a label\n",
        "df = df.dropna(subset=[\"student_star\"])"
      ],
      "metadata": {
        "id": "0ng-JJwG5wTz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae0d8bc0-b253-4223-be17-e2e374487527"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(array([693, 694, 695, 696, 697]),)\n",
            "(array([693, 694, 695, 696, 697]),)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if NaN were successfully removed\n",
        "print(np.where(np.isnan(df['student_star'])))\n",
        "print(np.where(np.isnan(df['student_difficult'])))\n",
        "\n",
        "print(\"New shape\", df.shape)"
      ],
      "metadata": {
        "id": "1Q1F9z0_5wQl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4708cee7-6884-42d9-d880-6f1d1220d9b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(array([], dtype=int64),)\n",
            "(array([], dtype=int64),)\n",
            "New shape (19995, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract comments, student star rating, and student difficulty rating\n",
        "x = df[\"comments\"].astype(str).tolist()\n",
        "y_star = df.iloc[:, 1].values\n",
        "y_diff = df.iloc[:, 2].values\n",
        "\n",
        "print(type(x), type(y_star), type(y_diff))\n",
        "print(len(x), y_star.size, y_diff.size)"
      ],
      "metadata": {
        "id": "C3aM6X7q7H44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e91db493-4075-402e-f82a-0b5e69871879"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
            "19995 19995 19995\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Removes any character that is not a word or whitespace while lowercasing\n",
        "cleaning_x = []\n",
        "for i in x:\n",
        "  i = re.sub(r'[^\\w\\s]', ' ', i)\n",
        "  i = i.lower()\n",
        "  cleaning_x.append(i)\n",
        "\n",
        "# Remove \\\n",
        "cleaned_x = []\n",
        "for j in cleaning_x:\n",
        "  j = j.replace(\"\\\\\", \" \")\n",
        "  cleaned_x.append(j)\n",
        "\n",
        "# Remove stopwords if have time\n",
        "# Get NLTK stopwords\n",
        "nltk.download('stopwords')\n",
        "cleanest_text = []\n",
        "for q in cleaned_x:\n",
        "  words = q.split()\n",
        "  cleaned = []\n",
        "  for w in words:\n",
        "    if w not in set(stopwords.words('english')):\n",
        "      cleaned.append(w)\n",
        "  cleanest_text.append(' '.join(cleaned))\n",
        "\n",
        "#cleanest_text"
      ],
      "metadata": {
        "id": "glMMoE1N7dhj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7a37c1c-d8d9-43e9-8ba3-b314d60c2175"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(cleanest_text))\n",
        "print(cleanest_text[0])\n",
        "print(type(cleanest_text), type(y_star), type(y_diff))"
      ],
      "metadata": {
        "id": "FurptEerrVnh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00fc277f-5e55-4443-d0b1-5faf52c8e09d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19995\n",
            "class hard two one gen ed knockout content stimulating unlike classes actually participate pass sections easy offer extra credit every week funny dude much say\n",
            "<class 'list'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gather more data using techniques from Wei and Zou's EDA\n",
        "\n",
        "Resources:\n",
        "\n",
        "https://blog.paperspace.com/data-augmentation-for-nlp/\n",
        "\n",
        "https://arxiv.org/pdf/1901.11196.pdf"
      ],
      "metadata": {
        "id": "mlpAu8f2rYNs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine the x, ys, and yd to a single df\n",
        "aug_df = pd.DataFrame({\"Comments\":cleanest_text,\n",
        "                       \"Star\":y_star,\n",
        "                       \"Difficulty\":y_diff})\n",
        "aug_df.head(3)"
      ],
      "metadata": {
        "id": "ffY-YIcRrVhm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "3552b04c-91fd-442c-fd33-ece4a78c2e99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            Comments  Star  Difficulty\n",
              "0  class hard two one gen ed knockout content sti...   5.0         3.0\n",
              "1  definitely going choose prof looney class inte...   5.0         2.0\n",
              "2  overall enjoyed class assignments straightforw...   4.0         3.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-42017db2-c3ed-429c-b642-2f446de6240c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Comments</th>\n",
              "      <th>Star</th>\n",
              "      <th>Difficulty</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>class hard two one gen ed knockout content sti...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>definitely going choose prof looney class inte...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>overall enjoyed class assignments straightforw...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-42017db2-c3ed-429c-b642-2f446de6240c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-42017db2-c3ed-429c-b642-2f446de6240c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-42017db2-c3ed-429c-b642-2f446de6240c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract comments for preparation of data augmentation\n",
        "comments = aug_df[\"Comments\"].astype(str).tolist()\n",
        "comments[0:3]"
      ],
      "metadata": {
        "id": "ac1jwJ0KqH8j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6aaab40c-ed9e-4537-eafb-c1a317921aca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['class hard two one gen ed knockout content stimulating unlike classes actually participate pass sections easy offer extra credit every week funny dude much say',\n",
              " 'definitely going choose prof looney class interesting class easy bring notes exams need remember lot lots bonus points available observatory sessions awesome',\n",
              " 'overall enjoyed class assignments straightforward interesting enjoy video project felt like one group cared enough help']"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data augmentation with synonym, swap, and delete of the comments\n",
        "# at 20%. I chose a relatively low percentage to augment b/c the\n",
        "# new data should still have most of its meaning\n",
        "# Note: If time permits, maybe also try antonyms to diverse the data?\n",
        "data_augments = [\n",
        "  naw.SynonymAug(aug_p=0.2),\n",
        "  naw.RandomWordAug(action='swap', aug_p=0.2),\n",
        "  naw.RandomWordAug(action='delete', aug_p=0.2)\n",
        "]\n",
        "\n",
        "# Perform the 3 augmentations for each comment\n",
        "new_augmented_texts = []\n",
        "for c in comments:\n",
        "  for a in data_augments:\n",
        "    new_augmented_texts.append(a.augment(c))"
      ],
      "metadata": {
        "id": "W71FicN-qRSV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View the new augmented data\n",
        "print(new_augmented_texts)\n",
        "\n",
        "# Note: Data rate exceeded at 59985 augmented data"
      ],
      "metadata": {
        "id": "QLa6vb0GruC_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80497203-d21a-47fe-b786-5ee5cec5a4c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# View the new augmented data\n",
        "# Note: Due to the limit, I have to make do with 59985 samples.\n",
        "print(len(new_augmented_texts))\n",
        "new_augmented_texts[0:3]\n",
        "# Note: The first 3 are augmented of the original\n",
        "# Funny note: Since there is a term \"gen ed\", the synonym data\n",
        "#             augmentation replaced \"ed\" with \"erectile dysfunction\""
      ],
      "metadata": {
        "id": "k_fy9IhQswr2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64033751-2b82-400a-e034-aa7acafe9a03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "59985\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['family hard two one gen ed knockout content stimulating unlike classes actually participate pass sections easy bid extra cite every week funny fellow much say'],\n",
              " ['class hard two one gen ed knockout content stimulating classes unlike actually participate pass sections offer easy extra credit every funny week dude much say'],\n",
              " ['class hard two one gen ed knockout content stimulating unlike participate pass sections easy credit every week funny dude say']]"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# View the original non-augmented comment for comparison\n",
        "comments[0]"
      ],
      "metadata": {
        "id": "kbEgj6opswpD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "f6ff4da4-eef6-4052-d654-889cac61173b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'class hard two one gen ed knockout content stimulating unlike classes actually participate pass sections easy offer extra credit every week funny dude much say'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Since I have augmented the data with 3 augmentors,\n",
        "# the corresponding labels need to be of the same amount.\n",
        "# Since the structure of the augmented comments are in\n",
        "# order, due to the nested loop, can just use repeat.\n",
        "star = aug_df[\"Star\"].values\n",
        "aug_star = np.repeat(star, len(data_augments))\n",
        "\n",
        "diff = aug_df[\"Difficulty\"].values\n",
        "aug_diff = np.repeat(diff, len(data_augments))"
      ],
      "metadata": {
        "id": "-bjsWbubuxid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Double check that the labels corresponds to the correct sample\n",
        "print(diff[0:10])\n",
        "print(aug_diff[0:30])\n",
        "print()\n",
        "print(star[0:10])\n",
        "print(aug_star[0:30])\n",
        "# Seems like it"
      ],
      "metadata": {
        "id": "0kyd12XJuxfP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b49573a-2bb1-4277-8ffd-64ac2ad45b57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3. 2. 3. 3. 1. 2. 2. 2. 1. 2.]\n",
            "[3. 3. 3. 2. 2. 2. 3. 3. 3. 3. 3. 3. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
            " 1. 1. 1. 2. 2. 2.]\n",
            "\n",
            "[5. 5. 4. 5. 5. 5. 5. 5. 5. 5.]\n",
            "[5. 5. 5. 5. 5. 5. 4. 4. 4. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5.\n",
            " 5. 5. 5. 5. 5. 5.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Double check types again\n",
        "print(type(y_star), type(aug_star))\n",
        "print(type(y_diff), type(aug_diff))\n",
        "print(type(cleanest_text), type(new_augmented_texts))\n",
        "print()\n",
        "\n",
        "# Lengths\n",
        "print(y_star.size, aug_star.size)\n",
        "print(y_diff.size, aug_diff.size)\n",
        "print(len(cleanest_text), len(new_augmented_texts))\n",
        "print()\n",
        "\n",
        "# Length when combining\n",
        "print(len(cleanest_text) + len(new_augmented_texts))"
      ],
      "metadata": {
        "id": "R-o5ds-vxKUX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a9a9ab0-9ac6-4b15-d40c-6fe6eba34bcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
            "<class 'list'> <class 'list'>\n",
            "\n",
            "19995 59985\n",
            "19995 59985\n",
            "19995 59985\n",
            "\n",
            "79980\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine original data with augmented data\n",
        "# The order of samples do not matter, since it will be\n",
        "# shuffled during the splitting phase\n",
        "# Note: Also the data augmentation was performed on\n",
        "#       the pre-processed data, so no need to\n",
        "#       pre-process again."
      ],
      "metadata": {
        "id": "SOd_jSE9wZCr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# However, before combining make sure they are in the same format\n",
        "print(cleanest_text[0])\n",
        "print(new_augmented_texts[0])"
      ],
      "metadata": {
        "id": "Ka1V1uw-wY_p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2917775d-292c-47b9-9103-6b80704db106"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "class hard two one gen ed knockout content stimulating unlike classes actually participate pass sections easy offer extra credit every week funny dude much say\n",
            "['family hard two one gen ed knockout content stimulating unlike classes actually participate pass sections easy bid extra cite every week funny fellow much say']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# They are not the same format, so must convert\n",
        "# the augmented comments into just a list of strings\n",
        "cleanest_augmented_texts = []\n",
        "for k in new_augmented_texts:\n",
        "  for j in k:\n",
        "    cleanest_augmented_texts.append(j)\n",
        "\n",
        "# Make sure it is in the right format. Yes it is.\n",
        "print(cleanest_augmented_texts[0])"
      ],
      "metadata": {
        "id": "RL8cJ_6GqRPF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd1bed8e-1882-45bb-c8bf-8aa95a69121c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "family hard two one gen ed knockout content stimulating unlike classes actually participate pass sections easy bid extra cite every week funny fellow much say\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Okay. Now I merge the original and augmented dataset\n",
        "merged_texts = cleanest_text + cleanest_augmented_texts\n",
        "\n",
        "# Remember from before that the size should be 79980, so\n",
        "# double check\n",
        "print(len(merged_texts))"
      ],
      "metadata": {
        "id": "75sD8rMzyTbw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ade5ad0d-cdfb-4d29-dc1e-a1c84f98c72b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79920\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# There is 60 missing samples?\n",
        "# Let's investigate by looking at the lengths.\n",
        "print(len(merged_texts))\n",
        "print(len(cleanest_text) + len(new_augmented_texts))\n",
        "print(len(cleanest_text))\n",
        "print(len(cleanest_augmented_texts))\n",
        "print(len(new_augmented_texts))"
      ],
      "metadata": {
        "id": "-DGqiiulyTen",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa890fe9-567c-4e32-bcb2-83f6d4508240"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79920\n",
            "79980\n",
            "19995\n",
            "59925\n",
            "59985\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Some rate my professor comments will be one word, such as \"Awesome\"\n",
        "# So during the data augmentation process, since I also used a\n",
        "# \"delete\" method, this might cause no comments!\n",
        "# Check for empty lists\n",
        "emptiness = []\n",
        "for m in new_augmented_texts:\n",
        "  if not m:\n",
        "    emptiness.append(m)\n",
        "print(len(emptiness))"
      ],
      "metadata": {
        "id": "jeH0GEjB1SNz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17513f6f-4107-4ac5-e7e2-7896b35941af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# There are 60 empty lists. This is a good thing, as now I can\n",
        "# find the indices of these empty lists and remove them.\n",
        "empty_indices = []\n",
        "for i in range(len(new_augmented_texts)):\n",
        "  if not new_augmented_texts[i]:\n",
        "    empty_indices.append(i)\n",
        "print(empty_indices)"
      ],
      "metadata": {
        "id": "rsH9i4VQ2Y__",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c10a460f-9de7-408f-ed64-3b5db6ff7b66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1365, 1366, 1367, 1422, 1423, 1424, 9519, 9520, 9521, 11280, 11281, 11282, 11439, 11440, 11441, 12051, 12052, 12053, 12792, 12793, 12794, 13101, 13102, 13103, 14814, 14815, 14816, 17835, 17836, 17837, 22173, 22174, 22175, 26166, 26167, 26168, 26226, 26227, 26228, 27615, 27616, 27617, 34158, 34159, 34160, 34164, 34165, 34166, 34170, 34171, 34172, 41454, 41455, 41456, 46662, 46663, 46664, 53346, 53347, 53348]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Double check if these are actualy empty lists\n",
        "print(new_augmented_texts[empty_indices[42]])"
      ],
      "metadata": {
        "id": "M9bS83lalfXe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bee16e6-e46e-4ccd-c8c8-1cd9b8fa5445"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# After retrieving the empty lists' indices, remove\n",
        "def remove_emptiness(comments):\n",
        "  \"\"\"\n",
        "  This function will take in the list of comments and will\n",
        "  remove the empty lists.\n",
        "  Returns a new list of non-empty lists.\n",
        "  \"\"\"\n",
        "  fulfilled = []\n",
        "  for c in comments:\n",
        "    if c:\n",
        "      fulfilled.append(c)\n",
        "  return fulfilled\n",
        "# Ran into small error when trying to remove empty lists with empty_indices,\n",
        "# so just used this simpler method because I am not too familiar with\n",
        "# string manipulation"
      ],
      "metadata": {
        "id": "Luywqe3f7cJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Note: I had to split the data due to \"data rate exceeded\" again\n",
        "split1 = remove_emptiness(new_augmented_texts[0:10000])\n",
        "split2 = remove_emptiness(new_augmented_texts[10000:20000])\n",
        "split3 = remove_emptiness(new_augmented_texts[20000:30000])\n",
        "split4 = remove_emptiness(new_augmented_texts[30000:40000])\n",
        "split5 = remove_emptiness(new_augmented_texts[40000:50000])\n",
        "split6 = remove_emptiness(new_augmented_texts[50000:len(new_augmented_texts)])\n",
        "\n",
        "# Combine the splits\n",
        "cleaned_aug_comments = split1 + split2 + split3 + split4 + split5 + split6\n",
        "\n",
        "# Double check the length\n",
        "print(len(cleaned_aug_comments))"
      ],
      "metadata": {
        "id": "cQ8K5_yW7b23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b38ee9df-ee5d-4aaa-fb64-f77dfa88f084"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "59925\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Need to also drop the corresponding labels\n",
        "new_aug_star = np.delete(aug_star, empty_indices)\n",
        "new_aug_diff = np.delete(aug_diff, empty_indices)\n",
        "\n",
        "print(new_aug_star.size, new_aug_diff.size)"
      ],
      "metadata": {
        "id": "0xylNeIl9FTT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ddc4b46-3b4d-4335-cfc4-7a20e735c314"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "59925 59925\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Okay. Now I am able to finally merge the datasets properly\n",
        "\n",
        "Caution Note: Merge in the same corresponding order!"
      ],
      "metadata": {
        "id": "onHtn8Oh_Kli"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge the labels\n",
        "combined_star = np.concatenate((y_star, new_aug_star))\n",
        "combined_diff = np.concatenate((y_diff, new_aug_diff))\n",
        "\n",
        "# Sanity check again\n",
        "print(combined_star.size, combined_diff.size)"
      ],
      "metadata": {
        "id": "yOdEjC3y-ND5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2641559-8c80-40e0-d5a4-544b388000c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79920 79920\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Merget the cleaned comments\n",
        "combined_texts = cleanest_text + cleanest_augmented_texts\n",
        "\n",
        "# Sanity check again\n",
        "print(len(combined_texts))"
      ],
      "metadata": {
        "id": "PMq7obFvARf7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac5b0730-ff1c-428c-e7a2-bb466dba11ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79920\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization\n",
        "tokens = tf.keras.preprocessing.text.Tokenizer(num_words = 20000)\n",
        "\n",
        "# Index vocabulary, so can make sequence later\n",
        "tokens.fit_on_texts(combined_texts)\n",
        "\n",
        "# Convert the student comments to a sequence of integers\n",
        "integer_sequences = tokens.texts_to_sequences(combined_texts)\n",
        "\n",
        "# Take a look at one student comment in the form of an integer sequence\n",
        "print(integer_sequences[69])\n",
        "\n",
        "# Sanity check again.\n",
        "print(len(integer_sequences))"
      ],
      "metadata": {
        "id": "1vf3ztcu2jEK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e66bf8f-b3df-4743-c920-40f9bfdbec09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[90, 1167, 50, 3332, 1387, 154, 39, 16, 281, 44, 43, 146, 777, 411, 4057, 1, 1498, 25, 5331, 624, 1103, 168, 1117, 388, 2007, 2432, 1]\n",
            "79920\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find and set max length from sequences in preparation to pad\n",
        "max_length = 0\n",
        "for k in integer_sequences:\n",
        "  if len(k) > max_length:\n",
        "    max_length = len(k)\n",
        "print(max_length)"
      ],
      "metadata": {
        "id": "VuAj3nquBIer",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e555087-95a8-41a6-adea-3ae114842e50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "72\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Padding the sequence to make them all the same lengths\n",
        "# Note: Sequences must have same length to feed into NN\n",
        "# Note: padding = \"post\" or \"pre\" produced similar performance results\n",
        "padded_sequences = tf.keras.utils.pad_sequences(integer_sequences,\n",
        "                                                maxlen = max_length,\n",
        "                                                padding = \"post\")\n",
        "# Sanity check\n",
        "print(padded_sequences.shape)\n",
        "print(padded_sequences[69])\n",
        "print(integer_sequences[69])"
      ],
      "metadata": {
        "id": "Yjr_t8jSC28k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e10cf66f-9553-4a42-a6ec-6e298af100c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(79920, 72)\n",
            "[  90 1167   50 3332 1387  154   39   16  281   44   43  146  777  411\n",
            " 4057    1 1498   25 5331  624 1103  168 1117  388 2007 2432    1    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0]\n",
            "[90, 1167, 50, 3332, 1387, 154, 39, 16, 281, 44, 43, 146, 777, 411, 4057, 1, 1498, 25, 5331, 624, 1103, 168, 1117, 388, 2007, 2432, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load in Stanford's GloVe, which is a pre-trained word embedding application\n",
        "\n",
        "Note: From Chollet's Deep Learning textbook"
      ],
      "metadata": {
        "id": "1zD89TDfCLvm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_index = {}\n",
        "with open(\"./drive/MyDrive/Datasets/glove.6B.100d.txt\") as f:\n",
        "  for line in f:\n",
        "    word, coefs = line.split(maxsplit = 1)\n",
        "    coefs = np.fromstring(coefs, \"f\" ,sep = \" \")\n",
        "    embeddings_index[word] = coefs\n",
        "\n",
        "print(\"Found %s word vectors.\" % len(embeddings_index))\n",
        "#embeddings_index.keys()\n",
        "#embeddings_index['is']"
      ],
      "metadata": {
        "id": "kPCzsSogWKnE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef3da298-3bcf-4960-f789-bb862ceb2233"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 400000 word vectors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparing/Creating the GloVe word-embeddings matrix\n",
        "embedding_dimensions = 100\n",
        "word_index = tokens.word_index\n",
        "\n",
        "embedding_matrix = np.zeros((len(word_index) + 1, embedding_dimensions))\n",
        "for word, i in word_index.items():\n",
        "  embedding_vector = embeddings_index.get(word)\n",
        "  if embedding_vector is not None:\n",
        "    embedding_matrix[i] = embedding_vector"
      ],
      "metadata": {
        "id": "jzLr_QuCXtOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(embedding_matrix.shape)"
      ],
      "metadata": {
        "id": "eAbOnY-H6kZe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "974de109-7a65-4a9a-df69-285afadfdd0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20276, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Embedding layer\n",
        "embedding_layer = tf.keras.layers.Embedding(input_dim = len(word_index) + 1,\n",
        "                                            output_dim = embedding_dimensions,\n",
        "                                            input_length = max_length,\n",
        "                                            weights = [embedding_matrix],\n",
        "                                            trainable = False,\n",
        "                                            mask_zero=True)"
      ],
      "metadata": {
        "id": "uAaz7RAdapQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(padded_sequences.shape)\n",
        "print(padded_sequences[0].shape[0])"
      ],
      "metadata": {
        "id": "Nn0oCRZdEvmQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b3840c7-c032-4bb9-83c5-ec747e52781d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(79920, 72)\n",
            "72\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# I made a mistake of embedding it twice. This will yield some rather\n",
        "# interesting findings... (such as the extra dimension and with reshaping\n",
        "# yielded extremely poor performance)"
      ],
      "metadata": {
        "id": "qn7iNxfIEvS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splitting the data (augmented plus original) into 60% training, 20% validation, 20% testing while shuffling"
      ],
      "metadata": {
        "id": "Afle1gLVI-BG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare data for splitting\n",
        "x_np = padded_sequences\n",
        "print(x_np.shape, type(x_np))\n",
        "print(combined_star.shape, combined_diff.shape)"
      ],
      "metadata": {
        "id": "e3mHXUGBcvz1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0dc136ea-2117-480b-f0d2-4621f4c6d449"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(79920, 72) <class 'numpy.ndarray'>\n",
            "(79920,) (79920,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_tv, x_test, ys_tv, ys_test, yd_tv, yd_test = train_test_split(\n",
        "    x_np, combined_star, combined_diff, test_size = 0.2, shuffle = True)\n",
        "\n",
        "x_train, x_val, ys_train, ys_val, yd_train, yd_val = train_test_split(\n",
        "    x_tv, ys_tv, yd_tv, test_size = 0.25, shuffle = True)\n",
        "\n",
        "# Sanity check\n",
        "print(x_train.shape, x_val.shape, x_test.shape)\n",
        "print(ys_train.shape, ys_val.shape, ys_test.shape)\n",
        "print(yd_train.shape, yd_val.shape, yd_test.shape)"
      ],
      "metadata": {
        "id": "Pc9N0lidJGAM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f747189-7055-4dcd-b023-c2a84d5d1feb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(47952, 72) (15984, 72) (15984, 72)\n",
            "(47952,) (15984,) (15984,)\n",
            "(47952,) (15984,) (15984,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# One-hot-encoding the labels\n",
        "ys_train = tf.keras.utils.to_categorical(ys_train, num_classes = 9)\n",
        "ys_val = tf.keras.utils.to_categorical(ys_val, num_classes = 9)\n",
        "ys_test = tf.keras.utils.to_categorical(ys_test, num_classes = 9)\n",
        "yd_train = tf.keras.utils.to_categorical(yd_train, num_classes = 9)\n",
        "yd_val = tf.keras.utils.to_categorical(yd_val, num_classes = 9)\n",
        "yd_test = tf.keras.utils.to_categorical(yd_test, num_classes = 9)"
      ],
      "metadata": {
        "id": "-Fa9wDn3ThHX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply early stopping regularisation technique\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor = \"val_loss\",\n",
        "                                                  patience = 3)"
      ],
      "metadata": {
        "id": "euWelTvgouxy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following are steps to model only using the original data and without adding augmented data.\n",
        "\n",
        "This is to compare to see if data augmentation will truly boost performance.\n"
      ],
      "metadata": {
        "id": "b45b1EGxx_LV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Original data with no augmented data\n",
        "# Comments are removed here, but if need extra clarifications then scroll up\n",
        "og_tokens = tf.keras.preprocessing.text.Tokenizer(num_words = 20000)\n",
        "og_tokens.fit_on_texts(cleanest_text)\n",
        "og_integer_sequences = og_tokens.texts_to_sequences(cleanest_text)\n",
        "print(og_integer_sequences[69])\n",
        "print(len(og_integer_sequences))\n",
        "\n",
        "og_max_length = 0\n",
        "for k in og_integer_sequences:\n",
        "  if len(k) > og_max_length:\n",
        "    og_max_length = len(k)\n",
        "print(og_max_length)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pt59vEdu3tW6",
        "outputId": "5cb25eb3-a8ed-4ed2-9bbf-eedb7b19bf00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[105, 1206, 51, 2985, 1279, 155, 32, 16, 274, 45, 43, 138, 766, 392, 3531, 1, 1456, 24, 5255, 698, 1052, 164, 1069, 380, 1859, 2208, 1]\n",
            "19995\n",
            "72\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "og_padded_sequences = tf.keras.utils.pad_sequences(og_integer_sequences,\n",
        "                                                maxlen = og_max_length,\n",
        "                                                padding = \"post\")\n",
        "print(og_padded_sequences.shape)\n",
        "print(og_padded_sequences[69])\n",
        "print(og_integer_sequences[69])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8YdBPP87-R5",
        "outputId": "dd5095ed-0f49-4ac7-9e1a-7bec854c2277"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(19995, 72)\n",
            "[ 105 1206   51 2985 1279  155   32   16  274   45   43  138  766  392\n",
            " 3531    1 1456   24 5255  698 1052  164 1069  380 1859 2208    1    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0]\n",
            "[105, 1206, 51, 2985, 1279, 155, 32, 16, 274, 45, 43, 138, 766, 392, 3531, 1, 1456, 24, 5255, 698, 1052, 164, 1069, 380, 1859, 2208, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "og_word_index = og_tokens.word_index\n",
        "og_embedding_matrix = np.zeros((len(og_word_index) + 1, embedding_dimensions))\n",
        "for word, i in word_index.items():\n",
        "  embedding_vector = embeddings_index.get(word)\n",
        "  if embedding_vector is not None:\n",
        "    embedding_matrix[i] = embedding_vector\n",
        "print(og_embedding_matrix.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8od7rDM17-Od",
        "outputId": "26a46911-78b3-42ac-b8e9-c556969afebb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(16228, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "og_embedding_layer = tf.keras.layers.Embedding(input_dim = len(og_word_index) + 1,\n",
        "                                            output_dim = embedding_dimensions,\n",
        "                                            input_length = og_max_length,\n",
        "                                            weights = [og_embedding_matrix],\n",
        "                                            trainable = False,\n",
        "                                            mask_zero = True)\n",
        "print(og_padded_sequences.shape)\n",
        "print(og_padded_sequences[0].shape[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QZom7u48DKk",
        "outputId": "da409846-2eb4-4f4a-e3ff-8722b4eecf03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(19995, 72)\n",
            "72\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "og_x_np = og_padded_sequences\n",
        "print(og_x_np.shape, type(og_x_np))\n",
        "print(y_star.shape, y_diff.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ur5leozt8Ejp",
        "outputId": "4a4da8ff-217f-42e7-f5af-ee62ca438271"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(19995, 72) <class 'numpy.ndarray'>\n",
            "(19995,) (19995,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "og_x_tv, og_x_test, og_ys_tv, og_ys_test, og_yd_tv, og_yd_test = train_test_split(\n",
        "    og_x_np, y_star, y_diff, test_size = 0.2, shuffle = True)\n",
        "og_x_train, og_x_val, og_ys_train, og_ys_val, og_yd_train, og_yd_val = train_test_split(\n",
        "    og_x_tv, og_ys_tv, og_yd_tv, test_size = 0.25, shuffle = True)\n",
        "print(og_x_train.shape, og_x_val.shape, og_x_test.shape)\n",
        "print(og_ys_train.shape, og_ys_val.shape, og_ys_test.shape)\n",
        "print(og_yd_train.shape, og_yd_val.shape, og_yd_test.shape)\n",
        "og_ys_train = tf.keras.utils.to_categorical(og_ys_train, num_classes = 9)\n",
        "og_ys_val = tf.keras.utils.to_categorical(og_ys_val, num_classes = 9)\n",
        "og_ys_test = tf.keras.utils.to_categorical(og_ys_test, num_classes = 9)\n",
        "og_yd_train = tf.keras.utils.to_categorical(og_yd_train, num_classes = 9)\n",
        "og_yd_val = tf.keras.utils.to_categorical(og_yd_val, num_classes = 9)\n",
        "og_yd_test = tf.keras.utils.to_categorical(og_yd_test, num_classes = 9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_1RlSfc7Q9l",
        "outputId": "a5701a64-5d95-4040-c243-c90479d2e54e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(11997, 72) (3999, 72) (3999, 72)\n",
            "(11997,) (3999,) (3999,)\n",
            "(11997,) (3999,) (3999,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the log directory for the TensorBoard\n",
        "log_bo_star_dir = \"logs_baselineo_star/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_bo_callback_star = tf.keras.callbacks.TensorBoard(log_dir = log_bo_star_dir,\n",
        "                                                      histogram_freq = 1)\n",
        "obaseline_model_star = tf.keras.Sequential()\n",
        "obaseline_model_star.add(og_embedding_layer)\n",
        "obaseline_model_star.add(tf.keras.layers.Bidirectional(tf.keras.layers.GRU(64)))\n",
        "obaseline_model_star.add(tf.keras.layers.Dropout(0.5))\n",
        "obaseline_model_star.add(tf.keras.layers.Dense(9, activation='softmax'))\n",
        "obaseline_model_star.summary()\n",
        "\n",
        "obaseline_model_star.compile(loss='categorical_crossentropy', optimizer=\"adam\",\n",
        "              metrics=['accuracy', 'mse', 'mae'])\n",
        "\n",
        "obaseline_model_star.fit(og_x_train, og_ys_train, validation_data=(og_x_val, og_ys_val),\n",
        "          epochs = 8, batch_size = 32,\n",
        "          callbacks = [early_stopping, tensorboard_bo_callback_star])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wm0Bwwa-yALB",
        "outputId": "cccc9dc9-30be-44ad-ffbc-88f91452b79b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 72, 100)           1622800   \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 128)              63744     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 9)                 1161      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,687,705\n",
            "Trainable params: 64,905\n",
            "Non-trainable params: 1,622,800\n",
            "_________________________________________________________________\n",
            "Epoch 1/8\n",
            "375/375 [==============================] - 26s 34ms/step - loss: 1.6030 - accuracy: 0.3428 - mse: 0.0863 - mae: 0.1723 - val_loss: 1.5295 - val_accuracy: 0.3591 - val_mse: 0.0846 - val_mae: 0.1707\n",
            "Epoch 2/8\n",
            "375/375 [==============================] - 10s 27ms/step - loss: 1.5295 - accuracy: 0.3473 - mse: 0.0849 - mae: 0.1693 - val_loss: 1.5141 - val_accuracy: 0.3591 - val_mse: 0.0842 - val_mae: 0.1681\n",
            "Epoch 3/8\n",
            "375/375 [==============================] - 9s 24ms/step - loss: 1.5191 - accuracy: 0.3522 - mse: 0.0845 - mae: 0.1686 - val_loss: 1.5105 - val_accuracy: 0.3591 - val_mse: 0.0841 - val_mae: 0.1690\n",
            "Epoch 4/8\n",
            "375/375 [==============================] - 11s 30ms/step - loss: 1.5171 - accuracy: 0.3516 - mse: 0.0845 - mae: 0.1687 - val_loss: 1.5070 - val_accuracy: 0.3591 - val_mse: 0.0839 - val_mae: 0.1682\n",
            "Epoch 5/8\n",
            "375/375 [==============================] - 11s 29ms/step - loss: 1.5148 - accuracy: 0.3529 - mse: 0.0844 - mae: 0.1685 - val_loss: 1.5079 - val_accuracy: 0.3591 - val_mse: 0.0840 - val_mae: 0.1689\n",
            "Epoch 6/8\n",
            "375/375 [==============================] - 10s 27ms/step - loss: 1.5139 - accuracy: 0.3519 - mse: 0.0844 - mae: 0.1686 - val_loss: 1.5112 - val_accuracy: 0.3591 - val_mse: 0.0841 - val_mae: 0.1664\n",
            "Epoch 7/8\n",
            "375/375 [==============================] - 10s 26ms/step - loss: 1.5140 - accuracy: 0.3519 - mse: 0.0844 - mae: 0.1685 - val_loss: 1.5035 - val_accuracy: 0.3586 - val_mse: 0.0838 - val_mae: 0.1682\n",
            "Epoch 8/8\n",
            "375/375 [==============================] - 11s 28ms/step - loss: 1.5124 - accuracy: 0.3519 - mse: 0.0843 - mae: 0.1684 - val_loss: 1.5071 - val_accuracy: 0.3586 - val_mse: 0.0840 - val_mae: 0.1681\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f979c8c0df0>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir logs_baselineo_star/fit --port 6007"
      ],
      "metadata": {
        "id": "mMKY7alc_ytt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model_star on test set\n",
        "obaseline_model_star_evaluation = obaseline_model_star.evaluate(og_x_test, og_ys_test)\n",
        "print(\"Original Model (star) test loss:\", obaseline_model_star_evaluation[0])\n",
        "print(\"Original Model (star) test accuracy:\", obaseline_model_star_evaluation[1])\n",
        "\n",
        "# Make predictions\n",
        "obaseline_ys_predictions = obaseline_model_star.predict(og_x_test)\n",
        "\n",
        "# See MAE and MSE\n",
        "print(\"Original Baseline Model (star) test MAE: \", mean_absolute_error(og_ys_test, obaseline_ys_predictions))\n",
        "print(\"Original Baseline Model (star) test MSE: \", mean_squared_error(og_ys_test, obaseline_ys_predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxkrltO323re",
        "outputId": "6d338d05-ecac-4aff-c6ae-4c3185f814b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "125/125 [==============================] - 1s 10ms/step - loss: 1.5265 - accuracy: 0.3453 - mse: 0.0849 - mae: 0.1690\n",
            "Original Model (star) test loss: 1.5264798402786255\n",
            "Original Model (star) test accuracy: 0.34533634781837463\n",
            "125/125 [==============================] - 3s 6ms/step\n",
            "Original Baseline Model (star) test MAE:  0.16904278\n",
            "Original Baseline Model (star) test MSE:  0.08486905\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "log_bo_diff_dir = \"logs_baselineo_diff/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_bo_callback_diff = tf.keras.callbacks.TensorBoard(log_dir = log_bo_diff_dir,\n",
        "                                                      histogram_freq = 1)\n",
        "obaseline_model_diff = tf.keras.Sequential()\n",
        "obaseline_model_diff.add(og_embedding_layer)\n",
        "obaseline_model_diff.add(tf.keras.layers.Bidirectional(tf.keras.layers.GRU(64)))\n",
        "obaseline_model_diff.add(tf.keras.layers.Dropout(0.5))\n",
        "obaseline_model_diff.add(tf.keras.layers.Dense(9, activation='softmax'))\n",
        "obaseline_model_diff.summary()\n",
        "\n",
        "obaseline_model_diff.compile(loss='categorical_crossentropy', optimizer = \"adam\",\n",
        "              metrics=['accuracy', 'mse', 'mae'])\n",
        "\n",
        "obaseline_model_diff.fit(og_x_train, og_yd_train, validation_data = (og_x_val, og_yd_val),\n",
        "          epochs = 8, batch_size = 32,\n",
        "          callbacks = [early_stopping, tensorboard_bo_callback_diff])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNT0IKIm23pA",
        "outputId": "e0b16515-32e9-410f-eace-93959ce158e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 72, 100)           1622800   \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 128)              63744     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 9)                 1161      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,687,705\n",
            "Trainable params: 64,905\n",
            "Non-trainable params: 1,622,800\n",
            "_________________________________________________________________\n",
            "Epoch 1/8\n",
            "375/375 [==============================] - 24s 36ms/step - loss: 1.6738 - accuracy: 0.2442 - mse: 0.0897 - mae: 0.1787 - val_loss: 1.6034 - val_accuracy: 0.2691 - val_mse: 0.0881 - val_mae: 0.1760\n",
            "Epoch 2/8\n",
            "375/375 [==============================] - 9s 25ms/step - loss: 1.6111 - accuracy: 0.2568 - mse: 0.0886 - mae: 0.1766 - val_loss: 1.5928 - val_accuracy: 0.2691 - val_mse: 0.0880 - val_mae: 0.1764\n",
            "Epoch 3/8\n",
            "375/375 [==============================] - 11s 28ms/step - loss: 1.6023 - accuracy: 0.2600 - mse: 0.0884 - mae: 0.1763 - val_loss: 1.5918 - val_accuracy: 0.2691 - val_mse: 0.0880 - val_mae: 0.1763\n",
            "Epoch 4/8\n",
            "375/375 [==============================] - 11s 28ms/step - loss: 1.5970 - accuracy: 0.2647 - mse: 0.0882 - mae: 0.1761 - val_loss: 1.5928 - val_accuracy: 0.2693 - val_mse: 0.0880 - val_mae: 0.1765\n",
            "Epoch 5/8\n",
            "375/375 [==============================] - 11s 28ms/step - loss: 1.5964 - accuracy: 0.2650 - mse: 0.0882 - mae: 0.1761 - val_loss: 1.5891 - val_accuracy: 0.2691 - val_mse: 0.0879 - val_mae: 0.1758\n",
            "Epoch 6/8\n",
            "375/375 [==============================] - 10s 25ms/step - loss: 1.5941 - accuracy: 0.2660 - mse: 0.0881 - mae: 0.1760 - val_loss: 1.5939 - val_accuracy: 0.2691 - val_mse: 0.0882 - val_mae: 0.1757\n",
            "Epoch 7/8\n",
            "375/375 [==============================] - 11s 30ms/step - loss: 1.5933 - accuracy: 0.2651 - mse: 0.0881 - mae: 0.1759 - val_loss: 1.5870 - val_accuracy: 0.2676 - val_mse: 0.0878 - val_mae: 0.1758\n",
            "Epoch 8/8\n",
            "375/375 [==============================] - 11s 30ms/step - loss: 1.5935 - accuracy: 0.2646 - mse: 0.0881 - mae: 0.1759 - val_loss: 1.5882 - val_accuracy: 0.2693 - val_mse: 0.0879 - val_mae: 0.1761\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f979d2ae080>"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir logs_baselineo_diff/fit --port 6008"
      ],
      "metadata": {
        "id": "VEv-0N2k_1Xo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model_diff on test set\n",
        "obaseline_model_diff_evaluation = obaseline_model_diff.evaluate(og_x_test, og_yd_test)\n",
        "print(\"Original Model (diff) test loss:\", obaseline_model_diff_evaluation[0])\n",
        "print(\"Original Model (diff) test accuracy:\", obaseline_model_diff_evaluation[1])\n",
        "\n",
        "# Make predictions\n",
        "obaseline_yd_predictions = obaseline_model_diff.predict(og_x_test)\n",
        "\n",
        "# See MAE and MSE\n",
        "print(\"Original Baseline Model (diff) test MAE: \", mean_absolute_error(og_yd_test, obaseline_yd_predictions))\n",
        "print(\"Original Baseline Model (diff) test MSE: \", mean_squared_error(og_yd_test, obaseline_yd_predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFQKlVg423lV",
        "outputId": "e1dfbe67-57f9-4152-c511-85f2d725e51f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "125/125 [==============================] - 1s 7ms/step - loss: 1.5870 - accuracy: 0.2723 - mse: 0.0878 - mae: 0.1760\n",
            "Original Model (diff) test loss: 1.5869672298431396\n",
            "Original Model (diff) test accuracy: 0.2723180651664734\n",
            "125/125 [==============================] - 4s 7ms/step\n",
            "Original Baseline Model (diff) test MAE:  0.17599066\n",
            "Original Baseline Model (diff) test MSE:  0.08782036\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: As one can see, the model ended up stagnating due to the small dataset. In other words, the model \"ran out of\" data to learn from. This is what provoked the idea, alongside with the instructor's suggestions in the project description, of gathering more data."
      ],
      "metadata": {
        "id": "_puxwoKl_PUK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In addition to the classification model, the regression model was also implemented. Prior to data augmentation, the regression model metrics yielded it was extremely overfitting and much more than the classification version. Therefore, the classification model was chosen to continue.\n",
        "\n",
        "Applications of L1, L2 and L1_l2 regularizations, additional layers, combinations of GRU and LSTM layers, configuring the number of nodes, dropout techniques, different learning rates, MinMaxScaling, and different optimizers were considered in constructing the final model."
      ],
      "metadata": {
        "id": "kB1Lwii8vlMo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Models using augmented data"
      ],
      "metadata": {
        "id": "cDnUNbFpCQY0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here I utilize two models, where model_star is to make predictions for star rating and model_diff is to make predictions for difficulty ratings. The following will be the baseline that utilizes the augmented data.\n",
        "\n",
        "Note: rmsprop and ADAM optimizers performed similarly"
      ],
      "metadata": {
        "id": "jO0m-iUhJ1IF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following will be the baseline model with data augmentation prior to hypertuning.\n",
        "\n",
        "The baseline model will consist of a simple architecture."
      ],
      "metadata": {
        "id": "9GRdunP0xFAh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the log directory for the TensorBoard\n",
        "log_b_star_dir = \"logs_baseline_star/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_b_callback_star = tf.keras.callbacks.TensorBoard(log_dir = log_b_star_dir,\n",
        "                                                      histogram_freq = 1)\n",
        "baseline_model_star = tf.keras.Sequential()\n",
        "baseline_model_star.add(embedding_layer)\n",
        "baseline_model_star.add(tf.keras.layers.Bidirectional(tf.keras.layers.GRU(64)))\n",
        "baseline_model_star.add(tf.keras.layers.Dropout(0.5))\n",
        "baseline_model_star.add(tf.keras.layers.Dense(9, activation='softmax'))\n",
        "baseline_model_star.summary()\n",
        "\n",
        "baseline_model_star.compile(loss='categorical_crossentropy', optimizer=\"adam\",\n",
        "              metrics=['accuracy', 'mse', 'mae'])\n",
        "\n",
        "baseline_model_star.fit(x_train, ys_train, validation_data=(x_val, ys_val),\n",
        "          epochs = 8, batch_size = 32,\n",
        "          callbacks = [early_stopping, tensorboard_b_callback_star])"
      ],
      "metadata": {
        "id": "jOJ3lHhkzDq9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa6c99c4-b54d-4aab-ddc0-16e762058b27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 74, 100)           2024000   \n",
            "                                                                 \n",
            " bidirectional_2 (Bidirectio  (None, 128)              63744     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 9)                 1161      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,088,905\n",
            "Trainable params: 64,905\n",
            "Non-trainable params: 2,024,000\n",
            "_________________________________________________________________\n",
            "Epoch 1/8\n",
            "1499/1499 [==============================] - 54s 28ms/step - loss: 1.2787 - accuracy: 0.4580 - mse: 0.0726 - mae: 0.1434 - val_loss: 1.1732 - val_accuracy: 0.4951 - val_mse: 0.0683 - val_mae: 0.1348\n",
            "Epoch 2/8\n",
            "1499/1499 [==============================] - 31s 21ms/step - loss: 1.1597 - accuracy: 0.5044 - mse: 0.0675 - mae: 0.1346 - val_loss: 1.1277 - val_accuracy: 0.5138 - val_mse: 0.0664 - val_mae: 0.1347\n",
            "Epoch 3/8\n",
            "1499/1499 [==============================] - 32s 21ms/step - loss: 1.1107 - accuracy: 0.5264 - mse: 0.0653 - mae: 0.1303 - val_loss: 1.0991 - val_accuracy: 0.5300 - val_mse: 0.0650 - val_mae: 0.1282\n",
            "Epoch 4/8\n",
            "1499/1499 [==============================] - 31s 20ms/step - loss: 1.0643 - accuracy: 0.5497 - mse: 0.0630 - mae: 0.1257 - val_loss: 1.0904 - val_accuracy: 0.5284 - val_mse: 0.0648 - val_mae: 0.1246\n",
            "Epoch 5/8\n",
            "1499/1499 [==============================] - 31s 21ms/step - loss: 1.0141 - accuracy: 0.5733 - mse: 0.0605 - mae: 0.1208 - val_loss: 1.0344 - val_accuracy: 0.5609 - val_mse: 0.0617 - val_mae: 0.1239\n",
            "Epoch 6/8\n",
            "1499/1499 [==============================] - 35s 23ms/step - loss: 0.9602 - accuracy: 0.5977 - mse: 0.0576 - mae: 0.1152 - val_loss: 1.0269 - val_accuracy: 0.5630 - val_mse: 0.0614 - val_mae: 0.1216\n",
            "Epoch 7/8\n",
            "1499/1499 [==============================] - 31s 20ms/step - loss: 0.9056 - accuracy: 0.6251 - mse: 0.0545 - mae: 0.1092 - val_loss: 1.0043 - val_accuracy: 0.5793 - val_mse: 0.0597 - val_mae: 0.1177\n",
            "Epoch 8/8\n",
            "1499/1499 [==============================] - 31s 21ms/step - loss: 0.8573 - accuracy: 0.6460 - mse: 0.0517 - mae: 0.1036 - val_loss: 0.9919 - val_accuracy: 0.5791 - val_mse: 0.0595 - val_mae: 0.1166\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9797ab9750>"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir logs_baseline_star/fit --port 6009"
      ],
      "metadata": {
        "id": "JjvlmsfpCjng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model_star on test set\n",
        "baseline_model_star_evaluation = baseline_model_star.evaluate(x_test, ys_test)\n",
        "print(\"Baseline Model (star) test loss:\", baseline_model_star_evaluation[0])\n",
        "print(\"Baseline Model (star) test accuracy:\", baseline_model_star_evaluation[1])\n",
        "\n",
        "# Make predictions\n",
        "baseline_ys_predictions = baseline_model_star.predict(x_test)\n",
        "\n",
        "# See MAE and MSE\n",
        "print(\"Baseline Model (star) test MAE: \", mean_absolute_error(ys_test, baseline_ys_predictions))\n",
        "print(\"Baseline Model (star) test MSE: \", mean_squared_error(ys_test, baseline_ys_predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ehPP17po7No",
        "outputId": "67794dc6-b51a-449a-e89c-a2963df0ffb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "500/500 [==============================] - 4s 7ms/step - loss: 0.9881 - accuracy: 0.5828 - mse: 0.0594 - mae: 0.1167\n",
            "Baseline Model (star) test loss: 0.9880515933036804\n",
            "Baseline Model (star) test accuracy: 0.5828328132629395\n",
            "500/500 [==============================] - 4s 5ms/step\n",
            "Baseline Model (star) test MAE:  0.116656095\n",
            "Baseline Model (star) test MSE:  0.059395954\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Also run on the y_difficulty"
      ],
      "metadata": {
        "id": "XWQXEyX_KH4x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "log_b_diff_dir = \"logs_baseline_diff/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_b_callback_diff = tf.keras.callbacks.TensorBoard(log_dir = log_b_diff_dir,\n",
        "                                                      histogram_freq = 1)\n",
        "baseline_model_diff = tf.keras.Sequential()\n",
        "baseline_model_diff.add(embedding_layer)\n",
        "baseline_model_diff.add(tf.keras.layers.Bidirectional(tf.keras.layers.GRU(64)))\n",
        "baseline_model_diff.add(tf.keras.layers.Dropout(0.5))\n",
        "baseline_model_diff.add(tf.keras.layers.Dense(9, activation='softmax'))\n",
        "baseline_model_diff.summary()\n",
        "\n",
        "baseline_model_diff.compile(loss='categorical_crossentropy', optimizer = \"adam\",\n",
        "              metrics=['accuracy', 'mse', 'mae'])\n",
        "\n",
        "baseline_model_diff.fit(x_train, yd_train, validation_data = (x_val, yd_val),\n",
        "          epochs = 8, batch_size = 32,\n",
        "          callbacks = [early_stopping, tensorboard_b_callback_diff])"
      ],
      "metadata": {
        "id": "PP8JC_CpE4wu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4c1f414-7665-4a86-81d5-e9e2b62b57da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 74, 100)           2024000   \n",
            "                                                                 \n",
            " bidirectional_3 (Bidirectio  (None, 128)              63744     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 9)                 1161      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,088,905\n",
            "Trainable params: 64,905\n",
            "Non-trainable params: 2,024,000\n",
            "_________________________________________________________________\n",
            "Epoch 1/8\n",
            "1499/1499 [==============================] - 45s 24ms/step - loss: 1.5275 - accuracy: 0.3153 - mse: 0.0849 - mae: 0.1676 - val_loss: 1.4367 - val_accuracy: 0.3647 - val_mse: 0.0813 - val_mae: 0.1636\n",
            "Epoch 2/8\n",
            "1499/1499 [==============================] - 31s 20ms/step - loss: 1.4314 - accuracy: 0.3671 - mse: 0.0811 - mae: 0.1618 - val_loss: 1.4177 - val_accuracy: 0.3697 - val_mse: 0.0807 - val_mae: 0.1609\n",
            "Epoch 3/8\n",
            "1499/1499 [==============================] - 31s 21ms/step - loss: 1.3958 - accuracy: 0.3849 - mse: 0.0796 - mae: 0.1589 - val_loss: 1.3890 - val_accuracy: 0.3903 - val_mse: 0.0793 - val_mae: 0.1583\n",
            "Epoch 4/8\n",
            "1499/1499 [==============================] - 34s 23ms/step - loss: 1.3582 - accuracy: 0.4090 - mse: 0.0777 - mae: 0.1552 - val_loss: 1.3640 - val_accuracy: 0.3967 - val_mse: 0.0781 - val_mae: 0.1560\n",
            "Epoch 5/8\n",
            "1499/1499 [==============================] - 32s 21ms/step - loss: 1.3164 - accuracy: 0.4341 - mse: 0.0756 - mae: 0.1511 - val_loss: 1.3342 - val_accuracy: 0.4181 - val_mse: 0.0766 - val_mae: 0.1528\n",
            "Epoch 6/8\n",
            "1499/1499 [==============================] - 31s 21ms/step - loss: 1.2577 - accuracy: 0.4639 - mse: 0.0726 - mae: 0.1453 - val_loss: 1.2929 - val_accuracy: 0.4455 - val_mse: 0.0744 - val_mae: 0.1485\n",
            "Epoch 7/8\n",
            "1499/1499 [==============================] - 31s 21ms/step - loss: 1.1936 - accuracy: 0.5012 - mse: 0.0691 - mae: 0.1384 - val_loss: 1.2967 - val_accuracy: 0.4505 - val_mse: 0.0742 - val_mae: 0.1462\n",
            "Epoch 8/8\n",
            "1499/1499 [==============================] - 31s 21ms/step - loss: 1.1321 - accuracy: 0.5303 - mse: 0.0658 - mae: 0.1320 - val_loss: 1.2527 - val_accuracy: 0.4739 - val_mse: 0.0720 - val_mae: 0.1401\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9769249ba0>"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir logs_baseline_diff/fit --port 6010"
      ],
      "metadata": {
        "id": "uRwJ3aDSCmhH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model_diff on test set\n",
        "baseline_model_diff_evaluation = baseline_model_diff.evaluate(x_test, yd_test)\n",
        "print(\"Baseline Model (diff) test loss:\", baseline_model_diff_evaluation[0])\n",
        "print(\"Baseline Model (diff) test accuracy:\", baseline_model_diff_evaluation[1])\n",
        "\n",
        "# Make predictions\n",
        "baseline_yd_predictions = baseline_model_diff.predict(x_test)\n",
        "\n",
        "# See MAE and MSE\n",
        "print(\"Baseline Model (diff) test MAE: \", mean_absolute_error(yd_test, baseline_yd_predictions))\n",
        "print(\"Baseline Model (diff) test MSE: \", mean_squared_error(yd_test, baseline_yd_predictions))"
      ],
      "metadata": {
        "id": "ucVUir5bE4tm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4508d838-8e75-4a01-aa48-51d4a8d81cb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "500/500 [==============================] - 3s 6ms/step - loss: 1.2667 - accuracy: 0.4747 - mse: 0.0724 - mae: 0.1405\n",
            "Baseline Model (diff) test loss: 1.2666878700256348\n",
            "Baseline Model (diff) test accuracy: 0.4746621549129486\n",
            "500/500 [==============================] - 4s 5ms/step\n",
            "Baseline Model (diff) test MAE:  0.14045009\n",
            "Baseline Model (diff) test MSE:  0.07239273\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hypertuning the two models with regularization techniques and more an additional bidrectional GRU layer, but with less units."
      ],
      "metadata": {
        "id": "vj-_FLcE6lpP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "log_h1_star_dir = \"logs_h1_star/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_h1_callback_star = tf.keras.callbacks.TensorBoard(log_dir = log_h1_star_dir,\n",
        "                                                      histogram_freq = 1)\n",
        "h1_model_star = tf.keras.Sequential()\n",
        "h1_model_star.add(embedding_layer)\n",
        "h1_model_star.add(tf.keras.layers.Bidirectional(tf.keras.layers.GRU(64, return_sequences = True,\n",
        "                                                                 kernel_regularizer = tf.keras.regularizers.l2(0.000001),\n",
        "                                                                 bias_regularizer = tf.keras.regularizers.l2(0.000001))))\n",
        "h1_model_star.add(tf.keras.layers.Bidirectional(tf.keras.layers.GRU(32,\n",
        "                                                                 kernel_regularizer = tf.keras.regularizers.l2(0.000001),\n",
        "                                                                 bias_regularizer = tf.keras.regularizers.l2(0.000001))))\n",
        "h1_model_star.add(tf.keras.layers.Dropout(0.5))\n",
        "h1_model_star.add(tf.keras.layers.Dense(9, activation='softmax'))\n",
        "\n",
        "h1_model_star.summary()\n",
        "\n",
        "h1_model_star.compile(loss='categorical_crossentropy', optimizer=\"adam\",\n",
        "              metrics=['accuracy', 'mse', 'mae'])\n",
        "\n",
        "h1_model_star.fit(x_train, ys_train, validation_data=(x_val, ys_val),\n",
        "          epochs = 8, batch_size = 32,\n",
        "          callbacks = [early_stopping, tensorboard_h1_callback_star])"
      ],
      "metadata": {
        "id": "n4KFhj5WE4qa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ae05f18-dc13-4114-d912-9b03706b902d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 74, 100)           2024000   \n",
            "                                                                 \n",
            " bidirectional_4 (Bidirectio  (None, 74, 128)          63744     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " bidirectional_5 (Bidirectio  (None, 64)               31104     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 9)                 585       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,119,433\n",
            "Trainable params: 95,433\n",
            "Non-trainable params: 2,024,000\n",
            "_________________________________________________________________\n",
            "Epoch 1/8\n",
            "1499/1499 [==============================] - 78s 40ms/step - loss: 1.2699 - accuracy: 0.4626 - mse: 0.0722 - mae: 0.1427 - val_loss: 1.1565 - val_accuracy: 0.5055 - val_mse: 0.0677 - val_mae: 0.1382\n",
            "Epoch 2/8\n",
            "1499/1499 [==============================] - 55s 37ms/step - loss: 1.1484 - accuracy: 0.5127 - mse: 0.0670 - mae: 0.1335 - val_loss: 1.1175 - val_accuracy: 0.5213 - val_mse: 0.0660 - val_mae: 0.1337\n",
            "Epoch 3/8\n",
            "1499/1499 [==============================] - 56s 37ms/step - loss: 1.0867 - accuracy: 0.5390 - mse: 0.0641 - mae: 0.1280 - val_loss: 1.0814 - val_accuracy: 0.5338 - val_mse: 0.0643 - val_mae: 0.1263\n",
            "Epoch 4/8\n",
            "1499/1499 [==============================] - 55s 37ms/step - loss: 1.0251 - accuracy: 0.5670 - mse: 0.0610 - mae: 0.1221 - val_loss: 1.0653 - val_accuracy: 0.5454 - val_mse: 0.0635 - val_mae: 0.1234\n",
            "Epoch 5/8\n",
            "1499/1499 [==============================] - 53s 35ms/step - loss: 0.9527 - accuracy: 0.6006 - mse: 0.0572 - mae: 0.1146 - val_loss: 1.0196 - val_accuracy: 0.5667 - val_mse: 0.0609 - val_mae: 0.1172\n",
            "Epoch 6/8\n",
            "1499/1499 [==============================] - 57s 38ms/step - loss: 0.8790 - accuracy: 0.6352 - mse: 0.0532 - mae: 0.1069 - val_loss: 0.9807 - val_accuracy: 0.5937 - val_mse: 0.0584 - val_mae: 0.1116\n",
            "Epoch 7/8\n",
            "1499/1499 [==============================] - 56s 38ms/step - loss: 0.8041 - accuracy: 0.6689 - mse: 0.0487 - mae: 0.0981 - val_loss: 0.9535 - val_accuracy: 0.6102 - val_mse: 0.0565 - val_mae: 0.1091\n",
            "Epoch 8/8\n",
            "1499/1499 [==============================] - 56s 38ms/step - loss: 0.7321 - accuracy: 0.7023 - mse: 0.0444 - mae: 0.0898 - val_loss: 0.9483 - val_accuracy: 0.6188 - val_mse: 0.0556 - val_mae: 0.1034\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f97601c7850>"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir logs_h1_star/fit --port 6011"
      ],
      "metadata": {
        "id": "8yMQ98bqCpFd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h1_model_star_evaluation = h1_model_star.evaluate(x_test, ys_test)\n",
        "print(\"h1 Model (star) test loss:\", h1_model_star_evaluation[0])\n",
        "print(\"h1 Model (star) test accuracy:\", h1_model_star_evaluation[1])\n",
        "\n",
        "# Make predictions\n",
        "h1_ys_predictions = h1_model_star.predict(x_test)\n",
        "\n",
        "# See MAE and MSE\n",
        "print(\"h1 Model (star) test MAE: \", mean_absolute_error(ys_test, h1_ys_predictions))\n",
        "print(\"h1 Model (star) test MSE: \", mean_squared_error(ys_test, h1_ys_predictions))"
      ],
      "metadata": {
        "id": "7psmbLdA-zJv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5cde77c-9a5f-4e5e-fb18-7ff7edc059de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "500/500 [==============================] - 6s 12ms/step - loss: 0.9556 - accuracy: 0.6124 - mse: 0.0561 - mae: 0.1041\n",
            "h1 Model (star) test loss: 0.9555679559707642\n",
            "h1 Model (star) test accuracy: 0.6123623847961426\n",
            "500/500 [==============================] - 10s 10ms/step\n",
            "h1 Model (star) test MAE:  0.10414232\n",
            "h1 Model (star) test MSE:  0.05606264\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "log_h1_diff_dir = \"logs_h1_diff/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_h1_callback_diff = tf.keras.callbacks.TensorBoard(log_dir = log_h1_diff_dir,\n",
        "                                                      histogram_freq = 1)\n",
        "h1_model_diff = tf.keras.Sequential()\n",
        "h1_model_diff.add(embedding_layer)\n",
        "h1_model_diff.add(tf.keras.layers.Bidirectional(tf.keras.layers.GRU(64, return_sequences = True,\n",
        "                                                                 kernel_regularizer = tf.keras.regularizers.l2(0.000001),\n",
        "                                                                 bias_regularizer = tf.keras.regularizers.l2(0.000001))))\n",
        "h1_model_diff.add(tf.keras.layers.Bidirectional(tf.keras.layers.GRU(32,\n",
        "                                                                 kernel_regularizer = tf.keras.regularizers.l2(0.000001),\n",
        "                                                                 bias_regularizer = tf.keras.regularizers.l2(0.000001))))\n",
        "h1_model_diff.add(tf.keras.layers.Dropout(0.5))\n",
        "h1_model_diff.add(tf.keras.layers.Dense(9, activation='softmax'))\n",
        "h1_model_diff.summary()\n",
        "\n",
        "h1_model_diff.compile(loss='categorical_crossentropy', optimizer=\"adam\",\n",
        "              metrics=['accuracy', 'mse', 'mae'])\n",
        "\n",
        "h1_model_diff.fit(x_train, yd_train, validation_data=(x_val, yd_val),\n",
        "          epochs = 8, batch_size = 32,\n",
        "          callbacks = [early_stopping, tensorboard_h1_callback_diff])"
      ],
      "metadata": {
        "id": "7NiWB_LzhVFg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a28b1e1e-2f70-4f73-f0f6-ebc4982eaa2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 74, 100)           2024000   \n",
            "                                                                 \n",
            " bidirectional_6 (Bidirectio  (None, 74, 128)          63744     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " bidirectional_7 (Bidirectio  (None, 64)               31104     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 9)                 585       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,119,433\n",
            "Trainable params: 95,433\n",
            "Non-trainable params: 2,024,000\n",
            "_________________________________________________________________\n",
            "Epoch 1/8\n",
            "1499/1499 [==============================] - 79s 42ms/step - loss: 1.5221 - accuracy: 0.3202 - mse: 0.0846 - mae: 0.1673 - val_loss: 1.4354 - val_accuracy: 0.3660 - val_mse: 0.0813 - val_mae: 0.1633\n",
            "Epoch 2/8\n",
            "1499/1499 [==============================] - 53s 35ms/step - loss: 1.4232 - accuracy: 0.3743 - mse: 0.0807 - mae: 0.1611 - val_loss: 1.4022 - val_accuracy: 0.3821 - val_mse: 0.0799 - val_mae: 0.1597\n",
            "Epoch 3/8\n",
            "1499/1499 [==============================] - 56s 37ms/step - loss: 1.3747 - accuracy: 0.4006 - mse: 0.0785 - mae: 0.1569 - val_loss: 1.3688 - val_accuracy: 0.3997 - val_mse: 0.0784 - val_mae: 0.1573\n",
            "Epoch 4/8\n",
            "1499/1499 [==============================] - 57s 38ms/step - loss: 1.3174 - accuracy: 0.4334 - mse: 0.0757 - mae: 0.1514 - val_loss: 1.3274 - val_accuracy: 0.4261 - val_mse: 0.0762 - val_mae: 0.1523\n",
            "Epoch 5/8\n",
            "1499/1499 [==============================] - 56s 37ms/step - loss: 1.2355 - accuracy: 0.4775 - mse: 0.0715 - mae: 0.1432 - val_loss: 1.2876 - val_accuracy: 0.4525 - val_mse: 0.0740 - val_mae: 0.1467\n",
            "Epoch 6/8\n",
            "1499/1499 [==============================] - 54s 36ms/step - loss: 1.1398 - accuracy: 0.5309 - mse: 0.0662 - mae: 0.1332 - val_loss: 1.2564 - val_accuracy: 0.4732 - val_mse: 0.0720 - val_mae: 0.1401\n",
            "Epoch 7/8\n",
            "1499/1499 [==============================] - 55s 37ms/step - loss: 1.0400 - accuracy: 0.5753 - mse: 0.0606 - mae: 0.1222 - val_loss: 1.2786 - val_accuracy: 0.4851 - val_mse: 0.0719 - val_mae: 0.1337\n",
            "Epoch 8/8\n",
            "1499/1499 [==============================] - 55s 37ms/step - loss: 0.9524 - accuracy: 0.6172 - mse: 0.0556 - mae: 0.1119 - val_loss: 1.2572 - val_accuracy: 0.5014 - val_mse: 0.0711 - val_mae: 0.1299\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f97603cbd00>"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir logs_h1_diff/fit --port 6012"
      ],
      "metadata": {
        "id": "4E5oa78QCtEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model_diff on test set\n",
        "h1_model_diff_evaluation = h1_model_diff.evaluate(x_test, yd_test)\n",
        "print(\"h1 Model (diff) test loss:\", h1_model_diff_evaluation[0])\n",
        "print(\"h1 Model (diff) test accuracy:\", h1_model_diff_evaluation[1])\n",
        "\n",
        "# Make predictions\n",
        "h1_yd_predictions = h1_model_diff.predict(x_test)\n",
        "\n",
        "# See MAE and MSE\n",
        "print(\"h1 Model (diff) test MAE: \", mean_absolute_error(yd_test, h1_yd_predictions))\n",
        "print(\"h1 Model (diff) test MSE: \", mean_squared_error(yd_test, h1_yd_predictions))"
      ],
      "metadata": {
        "id": "fM_rL13K_0aM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7411cd95-a662-416a-9553-f7180e6555a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "500/500 [==============================] - 5s 10ms/step - loss: 1.2698 - accuracy: 0.4916 - mse: 0.0717 - mae: 0.1309\n",
            "h1 Model (diff) test loss: 1.2698380947113037\n",
            "h1 Model (diff) test accuracy: 0.4916166067123413\n",
            "500/500 [==============================] - 10s 9ms/step\n",
            "h1 Model (diff) test MAE:  0.13090636\n",
            "h1 Model (diff) test MSE:  0.071683496\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As one may see, adding an additional bidirectional GRU layers and regularizers improved a good ordeal.\n",
        "\n",
        "Let's see if applying dropout and recurrent_dropout to the GRU layers will improve the performance as well.\n",
        "\n",
        "This model with recurrent dropout and dropout for each of the 2 bidirectional GRUs has also been attempted, but due to taking an ETA of 30 minutes per epoch according to Google Colab and the following error, this model is being placed on hold and will continue with the h1 model.\n",
        "\n",
        "Note: WARNING:tensorflow:Layer gru_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU."
      ],
      "metadata": {
        "id": "y2WRFg0N2mTe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implement the best performing model, h1,  at a higher epoch 15. 20 would have been preferred, but choosing 15 due to time and GPU constraints."
      ],
      "metadata": {
        "id": "S4_ChZyPF06v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "log_hh1_star_dir = \"logs_hh1_star/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_hh1_callback_star = tf.keras.callbacks.TensorBoard(log_dir = log_hh1_star_dir,\n",
        "                                                      histogram_freq = 1)\n",
        "hh1_model_star = tf.keras.Sequential()\n",
        "hh1_model_star.add(embedding_layer)\n",
        "hh1_model_star.add(tf.keras.layers.Bidirectional(tf.keras.layers.GRU(64, return_sequences = True,\n",
        "                                                                 kernel_regularizer = tf.keras.regularizers.l2(0.000001),\n",
        "                                                                 bias_regularizer = tf.keras.regularizers.l2(0.000001))))\n",
        "hh1_model_star.add(tf.keras.layers.Bidirectional(tf.keras.layers.GRU(32,\n",
        "                                                                 kernel_regularizer = tf.keras.regularizers.l2(0.000001),\n",
        "                                                                 bias_regularizer = tf.keras.regularizers.l2(0.000001))))\n",
        "hh1_model_star.add(tf.keras.layers.Dropout(0.5))\n",
        "hh1_model_star.add(tf.keras.layers.Dense(9, activation='softmax'))\n",
        "\n",
        "hh1_model_star.summary()\n",
        "\n",
        "hh1_model_star.compile(loss='categorical_crossentropy', optimizer=\"adam\",\n",
        "              metrics=['accuracy', 'mse', 'mae'])\n",
        "\n",
        "hh1_model_star.fit(x_train, ys_train, validation_data=(x_val, ys_val),\n",
        "          epochs = 15, batch_size = 32,\n",
        "          callbacks = [early_stopping, tensorboard_hh1_callback_star])"
      ],
      "metadata": {
        "id": "5REUCZvxA2SP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80b97abe-64f9-43a5-f3ab-e08993bccf13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 72, 100)           2027600   \n",
            "                                                                 \n",
            " bidirectional_16 (Bidirecti  (None, 72, 128)          63744     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " bidirectional_17 (Bidirecti  (None, 64)               31104     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 9)                 585       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,123,033\n",
            "Trainable params: 95,433\n",
            "Non-trainable params: 2,027,600\n",
            "_________________________________________________________________\n",
            "Epoch 1/15\n",
            "1499/1499 [==============================] - 87s 46ms/step - loss: 1.2700 - accuracy: 0.4651 - mse: 0.0721 - mae: 0.1426 - val_loss: 1.1614 - val_accuracy: 0.5047 - val_mse: 0.0677 - val_mae: 0.1373\n",
            "Epoch 2/15\n",
            "1499/1499 [==============================] - 67s 45ms/step - loss: 1.1485 - accuracy: 0.5105 - mse: 0.0670 - mae: 0.1336 - val_loss: 1.1240 - val_accuracy: 0.5200 - val_mse: 0.0659 - val_mae: 0.1326\n",
            "Epoch 3/15\n",
            "1499/1499 [==============================] - 66s 44ms/step - loss: 1.0885 - accuracy: 0.5371 - mse: 0.0642 - mae: 0.1283 - val_loss: 1.0954 - val_accuracy: 0.5317 - val_mse: 0.0646 - val_mae: 0.1269\n",
            "Epoch 4/15\n",
            "1499/1499 [==============================] - 55s 37ms/step - loss: 1.0262 - accuracy: 0.5682 - mse: 0.0610 - mae: 0.1219 - val_loss: 1.0389 - val_accuracy: 0.5591 - val_mse: 0.0618 - val_mae: 0.1221\n",
            "Epoch 5/15\n",
            "1499/1499 [==============================] - 60s 40ms/step - loss: 0.9518 - accuracy: 0.6034 - mse: 0.0570 - mae: 0.1142 - val_loss: 1.0132 - val_accuracy: 0.5739 - val_mse: 0.0601 - val_mae: 0.1195\n",
            "Epoch 6/15\n",
            "1499/1499 [==============================] - 57s 38ms/step - loss: 0.8720 - accuracy: 0.6387 - mse: 0.0526 - mae: 0.1057 - val_loss: 0.9844 - val_accuracy: 0.5973 - val_mse: 0.0581 - val_mae: 0.1109\n",
            "Epoch 7/15\n",
            "1499/1499 [==============================] - 58s 38ms/step - loss: 0.7942 - accuracy: 0.6788 - mse: 0.0478 - mae: 0.0965 - val_loss: 0.9635 - val_accuracy: 0.6121 - val_mse: 0.0568 - val_mae: 0.1048\n",
            "Epoch 8/15\n",
            "1499/1499 [==============================] - 57s 38ms/step - loss: 0.7200 - accuracy: 0.7101 - mse: 0.0434 - mae: 0.0876 - val_loss: 0.9920 - val_accuracy: 0.6109 - val_mse: 0.0570 - val_mae: 0.1043\n",
            "Epoch 9/15\n",
            "1499/1499 [==============================] - 54s 36ms/step - loss: 0.6600 - accuracy: 0.7384 - mse: 0.0396 - mae: 0.0800 - val_loss: 0.9360 - val_accuracy: 0.6397 - val_mse: 0.0536 - val_mae: 0.0973\n",
            "Epoch 10/15\n",
            "1499/1499 [==============================] - 54s 36ms/step - loss: 0.5963 - accuracy: 0.7655 - mse: 0.0356 - mae: 0.0723 - val_loss: 0.9301 - val_accuracy: 0.6585 - val_mse: 0.0521 - val_mae: 0.0911\n",
            "Epoch 11/15\n",
            "1499/1499 [==============================] - 58s 39ms/step - loss: 0.5518 - accuracy: 0.7858 - mse: 0.0328 - mae: 0.0665 - val_loss: 0.9395 - val_accuracy: 0.6555 - val_mse: 0.0525 - val_mae: 0.0914\n",
            "Epoch 12/15\n",
            "1499/1499 [==============================] - 55s 37ms/step - loss: 0.5082 - accuracy: 0.8026 - mse: 0.0301 - mae: 0.0610 - val_loss: 0.9710 - val_accuracy: 0.6577 - val_mse: 0.0531 - val_mae: 0.0883\n",
            "Epoch 13/15\n",
            "1499/1499 [==============================] - 58s 39ms/step - loss: 0.4672 - accuracy: 0.8196 - mse: 0.0275 - mae: 0.0559 - val_loss: 0.9650 - val_accuracy: 0.6687 - val_mse: 0.0518 - val_mae: 0.0852\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f97a1d41660>"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir logs_hh1_star/fit --port 6013"
      ],
      "metadata": {
        "id": "kzEwYRp_A2Nf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hh1_model_star_evaluation = hh1_model_star.evaluate(x_test, ys_test)\n",
        "print(\"hh1 Model (star) test loss:\", hh1_model_star_evaluation[0])\n",
        "print(\"hh1 Model (star) test accuracy:\", hh1_model_star_evaluation[1])\n",
        "\n",
        "# Make predictions\n",
        "hh1_ys_predictions = hh1_model_star.predict(x_test)\n",
        "\n",
        "# See MAE and MSE\n",
        "print(\"hh1 Model (star) test MAE: \", mean_absolute_error(ys_test, hh1_ys_predictions))\n",
        "print(\"hh1 Model (star) test MSE: \", mean_squared_error(ys_test, hh1_ys_predictions))\n"
      ],
      "metadata": {
        "id": "2UZM4gCOSw-m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d1a3813-d60d-4562-e86a-69bfe9ad60f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "500/500 [==============================] - 5s 10ms/step - loss: 0.9485 - accuracy: 0.6745 - mse: 0.0513 - mae: 0.0847\n",
            "hh1 Model (star) test loss: 0.9485245943069458\n",
            "hh1 Model (star) test accuracy: 0.6744869947433472\n",
            "500/500 [==============================] - 9s 9ms/step\n",
            "hh1 Model (star) test MAE:  0.084676474\n",
            "hh1 Model (star) test MSE:  0.05126253\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "log_hh1_diff_dir = \"logs_hh1_diff/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_hh1_callback_diff = tf.keras.callbacks.TensorBoard(log_dir = log_hh1_diff_dir,\n",
        "                                                      histogram_freq = 1)\n",
        "hh1_model_diff = tf.keras.Sequential()\n",
        "hh1_model_diff.add(embedding_layer)\n",
        "hh1_model_diff.add(tf.keras.layers.Bidirectional(tf.keras.layers.GRU(64, return_sequences = True,\n",
        "                                                                 kernel_regularizer = tf.keras.regularizers.l2(0.000001),\n",
        "                                                                 bias_regularizer = tf.keras.regularizers.l2(0.000001))))\n",
        "hh1_model_diff.add(tf.keras.layers.Bidirectional(tf.keras.layers.GRU(32,\n",
        "                                                                 kernel_regularizer = tf.keras.regularizers.l2(0.000001),\n",
        "                                                                 bias_regularizer = tf.keras.regularizers.l2(0.000001))))\n",
        "hh1_model_diff.add(tf.keras.layers.Dropout(0.5))\n",
        "hh1_model_diff.add(tf.keras.layers.Dense(9, activation='softmax'))\n",
        "hh1_model_diff.summary()\n",
        "\n",
        "hh1_model_diff.compile(loss='categorical_crossentropy', optimizer=\"adam\",\n",
        "              metrics=['accuracy', 'mse', 'mae'])\n",
        "\n",
        "hh1_model_diff.fit(x_train, yd_train, validation_data=(x_val, yd_val),\n",
        "          epochs = 15, batch_size = 32,\n",
        "          callbacks = [early_stopping, tensorboard_hh1_callback_diff])"
      ],
      "metadata": {
        "id": "GcEjrSeqSw6u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f68e04ee-cc2f-4d58-83f4-1ac46fc007ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 72, 100)           2027600   \n",
            "                                                                 \n",
            " bidirectional_18 (Bidirecti  (None, 72, 128)          63744     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " bidirectional_19 (Bidirecti  (None, 64)               31104     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 9)                 585       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,123,033\n",
            "Trainable params: 95,433\n",
            "Non-trainable params: 2,027,600\n",
            "_________________________________________________________________\n",
            "Epoch 1/15\n",
            "1499/1499 [==============================] - 101s 40ms/step - loss: 1.5220 - accuracy: 0.3226 - mse: 0.0847 - mae: 0.1676 - val_loss: 1.4629 - val_accuracy: 0.3478 - val_mse: 0.0826 - val_mae: 0.1645\n",
            "Epoch 2/15\n",
            "1499/1499 [==============================] - 55s 37ms/step - loss: 1.4261 - accuracy: 0.3700 - mse: 0.0809 - mae: 0.1614 - val_loss: 1.4004 - val_accuracy: 0.3827 - val_mse: 0.0798 - val_mae: 0.1601\n",
            "Epoch 3/15\n",
            "1499/1499 [==============================] - 57s 38ms/step - loss: 1.3793 - accuracy: 0.3986 - mse: 0.0787 - mae: 0.1573 - val_loss: 1.3998 - val_accuracy: 0.3820 - val_mse: 0.0799 - val_mae: 0.1581\n",
            "Epoch 4/15\n",
            "1499/1499 [==============================] - 57s 38ms/step - loss: 1.3153 - accuracy: 0.4354 - mse: 0.0755 - mae: 0.1511 - val_loss: 1.3275 - val_accuracy: 0.4244 - val_mse: 0.0763 - val_mae: 0.1527\n",
            "Epoch 5/15\n",
            "1499/1499 [==============================] - 55s 37ms/step - loss: 1.2284 - accuracy: 0.4820 - mse: 0.0710 - mae: 0.1424 - val_loss: 1.2866 - val_accuracy: 0.4498 - val_mse: 0.0741 - val_mae: 0.1438\n",
            "Epoch 6/15\n",
            "1499/1499 [==============================] - 59s 39ms/step - loss: 1.1303 - accuracy: 0.5315 - mse: 0.0657 - mae: 0.1320 - val_loss: 1.2426 - val_accuracy: 0.4770 - val_mse: 0.0715 - val_mae: 0.1382\n",
            "Epoch 7/15\n",
            "1499/1499 [==============================] - 59s 39ms/step - loss: 1.0400 - accuracy: 0.5751 - mse: 0.0606 - mae: 0.1220 - val_loss: 1.2223 - val_accuracy: 0.4936 - val_mse: 0.0702 - val_mae: 0.1353\n",
            "Epoch 8/15\n",
            "1499/1499 [==============================] - 65s 44ms/step - loss: 0.9500 - accuracy: 0.6192 - mse: 0.0555 - mae: 0.1119 - val_loss: 1.1791 - val_accuracy: 0.5252 - val_mse: 0.0673 - val_mae: 0.1269\n",
            "Epoch 9/15\n",
            "1499/1499 [==============================] - 57s 38ms/step - loss: 0.8718 - accuracy: 0.6532 - mse: 0.0510 - mae: 0.1031 - val_loss: 1.1664 - val_accuracy: 0.5394 - val_mse: 0.0660 - val_mae: 0.1213\n",
            "Epoch 10/15\n",
            "1499/1499 [==============================] - 57s 38ms/step - loss: 0.8019 - accuracy: 0.6845 - mse: 0.0469 - mae: 0.0949 - val_loss: 1.1888 - val_accuracy: 0.5475 - val_mse: 0.0662 - val_mae: 0.1173\n",
            "Epoch 11/15\n",
            "1499/1499 [==============================] - 59s 39ms/step - loss: 0.7368 - accuracy: 0.7139 - mse: 0.0430 - mae: 0.0873 - val_loss: 1.1842 - val_accuracy: 0.5613 - val_mse: 0.0650 - val_mae: 0.1138\n",
            "Epoch 12/15\n",
            "1499/1499 [==============================] - 56s 38ms/step - loss: 0.6861 - accuracy: 0.7325 - mse: 0.0400 - mae: 0.0810 - val_loss: 1.2405 - val_accuracy: 0.5587 - val_mse: 0.0667 - val_mae: 0.1119\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f96e96d16f0>"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir logs_hh1_diff/fit --port 6014"
      ],
      "metadata": {
        "id": "7p5VWXFrSw2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model_diff on test set\n",
        "hh1_model_diff_evaluation = hh1_model_diff.evaluate(x_test, yd_test)\n",
        "print(\"hh1 Model (diff) test loss:\", hh1_model_diff_evaluation[0])\n",
        "print(\"hh1 Model (diff) test accuracy:\", hh1_model_diff_evaluation[1])\n",
        "\n",
        "# Make predictions\n",
        "hh1_yd_predictions = hh1_model_diff.predict(x_test)\n",
        "\n",
        "# See MAE and MSE\n",
        "print(\"hh1 Model (diff) test MAE: \", mean_absolute_error(yd_test, hh1_yd_predictions))\n",
        "print(\"hh1 Model (diff) test MSE: \", mean_squared_error(yd_test, hh1_yd_predictions))\n"
      ],
      "metadata": {
        "id": "v9xHt5MBTbcg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9df07bf-c703-476a-e65f-2fa531b58db9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "500/500 [==============================] - 4s 9ms/step - loss: 1.2499 - accuracy: 0.5590 - mse: 0.0670 - mae: 0.1125\n",
            "hh1 Model (diff) test loss: 1.2498631477355957\n",
            "hh1 Model (diff) test accuracy: 0.5589964985847473\n",
            "500/500 [==============================] - 9s 8ms/step\n",
            "hh1 Model (diff) test MAE:  0.11251475\n",
            "hh1 Model (diff) test MSE:  0.06696774\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In conclusion, it is clear from the results above that complicating the structure with an additional bidirectional GRU, as well as applying L2 regularization techniques to both bidirectional GRU layers, increased the performance drastically.\n",
        "\n",
        "For future work, incorporating recurrent dropouts and dropouts for each bidirectional GRU layer may yield increased performance."
      ],
      "metadata": {
        "id": "olds5Mp8TgtY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summary of results from model only using the original dataset without augmented data:\n",
        "\n",
        "Original Model (star) test accuracy: 0.34533634781837463\n",
        "\n",
        "Original Baseline Model (star) test MAE:  0.16904278\n",
        "\n",
        "Original Baseline Model (star) test MSE:  0.08486905\n",
        "\n",
        "Original Model (diff) test loss: 1.5869672298431396\n",
        "\n",
        "Original Model (diff) test accuracy: 0.2723180651664734\n",
        "\n",
        "Original Baseline Model (diff) test MAE:  0.17599066\n",
        "\n",
        "Original Baseline Model (diff) test MSE:  0.08782036"
      ],
      "metadata": {
        "id": "rli05isDdLPW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summary of results with models using augmented data in addition to the original dataset:\n",
        "\n",
        "Baseline Model (star) test loss: 0.9880515933036804\n",
        "\n",
        "Baseline Model (star) test accuracy: 0.5828328132629395\n",
        "\n",
        "Baseline Model (star) test MAE:  0.116656095\n",
        "\n",
        "Baseline Model (star) test MSE:  0.059395954\n",
        "\n",
        "Baseline Model (diff) test loss: 1.2666878700256348\n",
        "\n",
        "Baseline Model (diff) test accuracy: 0.4746621549129486\n",
        "\n",
        "Baseline Model (diff) test MAE:  0.14045009\n",
        "\n",
        "Baseline Model (diff) test MSE:  0.07239273\n",
        "\n",
        "Hypertuned Model (star) test loss: 0.9485245943069458\n",
        "\n",
        "Hypertuned Model (star) test accuracy: 0.6744869947433472\n",
        "\n",
        "Hypertuned Model (star) test MAE:  0.084676474\n",
        "\n",
        "Hypertuned Model (star) test MSE:  0.05126253\n",
        "\n",
        "Hypertuned Model (diff) test loss: 1.2498631477355957\n",
        "\n",
        "Hypertuned Model (diff) test accuracy: 0.5589964985847473\n",
        "\n",
        "Hypertuned Model (diff) test MAE:  0.11251475\n",
        "\n",
        "Hypertuned Model (diff) test MSE:  0.06696774"
      ],
      "metadata": {
        "id": "xKpcIE2zd5rL"
      }
    }
  ]
}